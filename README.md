# BetaBankChurns

Descripci√≥n del proyecto

Los clientes de Beta Bank se est√°n yendo poco a poco cada mes. Dado que es m√°s barato retener a los clientes existentes que adquirir nuevos, el banco busca una soluci√≥n para anticipar qu√© clientes est√°n en riesgo de abandonar.

Este proyecto consiste en desarrollar un modelo de Machine Learning que prediga si un cliente dejar√° el banco pr√≥ximamente, con el objetivo de ayudar a las √°reas de negocio a tomar decisiones preventivas.

‚∏ª

Objetivo
	‚Ä¢	Predecir si un cliente abandonar√° el banco (Exited).
	‚Ä¢	Maximizar la m√©trica F1-score (m√≠nimo requerido: 0.59).
	‚Ä¢	Comparar el rendimiento con la m√©trica AUC-ROC.

‚∏ª

Dataset

Archivo: Churn.csv

Caracter√≠sticas principales:
	‚Ä¢	RowNumber ‚Äì √≠ndice del registro.
	‚Ä¢	CustomerId ‚Äì identificador √∫nico del cliente.
	‚Ä¢	Surname ‚Äì apellido.
	‚Ä¢	CreditScore ‚Äì puntaje crediticio.
	‚Ä¢	Geography ‚Äì pa√≠s de residencia.
	‚Ä¢	Gender ‚Äì sexo.
	‚Ä¢	Age ‚Äì edad.
	‚Ä¢	Tenure ‚Äì antig√ºedad del cliente en el banco (a√±os).
	‚Ä¢	Balance ‚Äì saldo de la cuenta.
	‚Ä¢	NumOfProducts ‚Äì n√∫mero de productos bancarios contratados.
	‚Ä¢	HasCrCard ‚Äì tarjeta de cr√©dito (1 = s√≠, 0 = no).
	‚Ä¢	IsActiveMember ‚Äì actividad del cliente (1 = s√≠, 0 = no).
	‚Ä¢	EstimatedSalary ‚Äì salario estimado.

Variable objetivo:
	‚Ä¢	Exited ‚Äì si el cliente abandon√≥ el banco (1 = s√≠, 0 = no).

‚∏ª

Metodolog√≠a
	1.	Preparaci√≥n y preprocesamiento de datos
	‚Ä¢	Limpieza de valores y verificaci√≥n de tipos de datos.
	‚Ä¢	Codificaci√≥n de variables categ√≥ricas (Geography, Gender).
	‚Ä¢	Escalado de variables num√©ricas.
	2.	Exploraci√≥n de datos
	‚Ä¢	An√°lisis de distribuci√≥n de variables.
	‚Ä¢	Verificaci√≥n del desbalance de clases.
	3.	Modelos iniciales (baseline)
	‚Ä¢	Entrenamiento sin correcci√≥n de desbalance.
	‚Ä¢	Evaluaci√≥n de m√©tricas para establecer referencia.
	4.	Manejo del desbalance de clases
	‚Ä¢	Oversampling (SMOTE).
	‚Ä¢	Undersampling.
	‚Ä¢	Ajuste de pesos de clase en los algoritmos.
	5.	Entrenamiento y validaci√≥n de modelos
	‚Ä¢	Modelos probados: Logistic Regression, Random Forest, Gradient Boosting.
	‚Ä¢	B√∫squeda de hiperpar√°metros con GridSearchCV.
	‚Ä¢	Evaluaci√≥n en conjunto de validaci√≥n.
	6.	Prueba final
	‚Ä¢	Selecci√≥n del mejor modelo.
	‚Ä¢	Medici√≥n de F1-score y AUC-ROC en conjunto de prueba.

‚∏ª

Resultados
	‚Ä¢	Mejor modelo: [especificar, ej. Gradient Boosting]
	‚Ä¢	F1-score (test): [ej. 0.62]
	‚Ä¢	AUC-ROC (test): [ej. 0.84]

El modelo final supera el umbral requerido y demuestra buen poder de discriminaci√≥n entre clientes que abandonan y los que permanecen.

‚∏ª

üõ†Ô∏è Tecnolog√≠as utilizadas
	‚Ä¢	Python
	‚Ä¢	Pandas, NumPy ‚Äì manipulaci√≥n de datos.
	‚Ä¢	Scikit-learn ‚Äì modelos de Machine Learning y m√©tricas.
	‚Ä¢	Matplotlib, Seaborn ‚Äì visualizaci√≥n.
